<!doctype html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <title>Minimal by Steve Smith</title>

  <link rel="stylesheet" href="stylesheets/styles.css">
  <link rel="stylesheet" href="stylesheets/pygment_trac.css">
  <meta name="viewport" content="width=device-width">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
</head>

<body>
  <div class="wrapper">
    <header>
      <h1>Learning Markerless Robot-Depth Camera Calibration and End-Effector Pose Estimation</h1>
      <p><a href="https://scholar.google.com/citations?user=cnULLNAAAAAJ&hl=en" target="_blank"><strong>Bugra C.
            Sefercik</strong></a><br />
        <a href="https://scholar.google.com/citations?user=5sL0xZ4AAAAJ&hl=en" target="_blank"><strong>Baris
            Akgun</strong></a>
      </p>
      <p></p>

      <p class="view"><a href="https://openreview.net/pdf?id=eI8CZ2s267o" target="_blank"><b>View paper</b></a></p>

      <p class="view"><a href="https://github.com/bcsefercik/robot-camera-calibration" target="_blank">View the Project
          on GitHub
          <small>bcsefercik/robot-camera-calibration</small></a></p>

    </header>
    <section>
      <h1>System Demo Video</h1>
      <iframe width="100%" height="360" src="https://www.youtube.com/embed/97sP99G6C34" title="YouTube video player"
        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen></iframe>

      <h1>Task Setup</h1>
      <p><img src="images/task_setup.png" alt="Robot Camera Calibration Task Setup"></p>

      <h1>Abstract</h1>

      <p>Traditional approaches to extrinsic calibration use fiducial markers and learning-based approaches rely heavily
        on simulation data. In this work, we present a learning-based markerless extrinsic calibration system that uses
        a depth camera and does not rely on simulation data. We learn models for end-effector (EE) segmentation,
        single-frame rotation prediction and keypoint detection, from automatically generated real-world data. We use a
        transformation trick to get EE pose estimates from rotation predictions and a matching algorithm to get EE pose
        estimates from keypoint predictions. We further utilize the iterative closest point algorithm, multiple-frames,
        filtering and outlier detection to increase calibration robustness. Our evaluations with training data from
        multiple camera poses and test data from previously unseen poses give sub-centimeter and sub-deciradian average
        calibration and pose estimation errors. We also show that a carefully selected single training pose gives
        comparable results.</p>
    </section>
    <footer>

    </footer>
  </div>
  <script src="javascripts/scale.fix.js"></script>
</body>

</html>